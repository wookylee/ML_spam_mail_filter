{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "evaluation.ipynb",
      "provenance": [],
      "private_outputs": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "lHuxcx_sbQgK"
      },
      "source": [
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "from pandas import DataFrame\n",
        "import pickle\n",
        "import nltk\n",
        "\n",
        "\n",
        "drive.mount('/content/drive/')\n",
        "evaluation_data_path = '/content/drive/My Drive/기계학습/leaderboard_test_file.csv'\n",
        "cls_weight_path = '/content/drive/My Drive/기계학습/LR.pkl'\n",
        "cls_weight_path_2 = '/content/drive/My Drive/기계학습/DL.pkl'\n",
        "features_path = '/content/drive/My Drive/기계학습/features.pkl'\n",
        "result_path='/content/drive/My Drive/기계학습/result.csv'\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "\n",
        "data = pd.read_csv(evaluation_data_path)\n",
        "data.head()\n",
        "\n",
        "lr = pickle.load(open(cls_weight_path, 'rb'))\n",
        "features = pickle.load(open(features_path, 'rb'))\n",
        "#DR = pickle.load(open(cls_weight_path_2, 'rb'))\n",
        "\n",
        "\n",
        "def load_best_classifier():\n",
        "    model = lr\n",
        "    \n",
        "    return model\n",
        "\n",
        "\n",
        "def read_csv_and_classify(sparce_matrix, cls_model):\n",
        "    print(sparce_matrix)\n",
        "    print(len(sparce_matrix))\n",
        "    print(len(sparce_matrix[0]))\n",
        "    scores = cls_model.predict(sparce_matrix)\n",
        "    print(scores)\n",
        "    scores = scores.astype(np.uint8)\n",
        "    print(scores)\n",
        "    return scores\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "from google.colab import files\n",
        "\n",
        "\n",
        "#with open(evaluation_data_path, \"r\") as data:\n",
        "#     eval_lines = f.read().strip().split(\"\\n\")\n",
        "#     eval_header = eval_lines[0]\n",
        "#     eval_data = eval_lines[1:]\n",
        "# eval_data = np.array([[ff  if ff!=\"\" else \"nan\" for ff in fff.strip().split(\",\")] for fff in eval_data], dtype=np.float32)\n",
        "\n",
        "\n",
        "import nltk as nlp\n",
        "import re\n",
        "description_list = []\n",
        "for description in data['message']:\n",
        "    description = re.sub(\"[^a-zA-Z]\",\" \",description)\n",
        "    description = description.lower()   \n",
        "    description = nlp.word_tokenize(description)\n",
        "    #description = [ word for word in description if not word in set(stopwords.words(\"english\"))]\n",
        "    lemma = nlp.WordNetLemmatizer()\n",
        "    description = [ lemma.lemmatize(word) for word in description]\n",
        "    description = \" \".join(description)\n",
        "    description_list.append(description)\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer \n",
        "max_features = 3000 #We use the most common word\n",
        "print(features)\n",
        "count_vectorizer = CountVectorizer( vocabulary = features ,max_features = max_features, stop_words = \"english\")\n",
        "sparce_matrix = count_vectorizer.fit_transform(description_list).toarray()\n",
        "print(sparce_matrix)\n",
        "print(len(sparce_matrix))\n",
        "print(len(sparce_matrix[0]))\n",
        "\n",
        "print(\"the most using {} words: {}\".format(max_features,count_vectorizer.get_feature_names()))\n",
        "#sparce_matrix=[sparce_matrix zeros(size(sparse_matrix,1),3000-len(sparce_matrix[0]))]\n",
        "\n",
        "# if len(sparce_matrix[0])<5995:\n",
        "#     margin_matrix = np.zeros((len(sparce_matrix),5995-len(sparce_matrix[0])))\n",
        "#     sparce_matrix = np.hstack((sparce_matrix,margin_matrix))\n",
        "# print(sparce_matrix)\n",
        "# print(len(sparce_matrix))\n",
        "# print(len(sparce_matrix[0]))\n",
        "\n",
        "\n",
        "best_classification_model = load_best_classifier()\n",
        "\n",
        "cls_scores = read_csv_and_classify(sparce_matrix, best_classification_model)\n",
        "#print(len(cls_scores))\n",
        "\n",
        "cls_scores = cls_scores[0:len(data)]\n",
        "assert cls_scores.shape==(len(data),), \"Classification score shape mismatch\"\n",
        "assert cls_scores.dtype==np.uint8, \"Classification score data type mismatch\"\n",
        "\n",
        "res_score = pd.DataFrame({'label' : cls_scores})\n",
        "\n",
        "res_score.to_csv(result_path,index = False)\n",
        "# data[:, 2] = cls_scores\n",
        "# with open(evaluation_data_path, \"w\") as f:\n",
        "#     f.write(eval_header+\"\\n\"+\"\\n\".join([\",\".join([str(ff) for ff in fff]) for fff in data]))\n",
        " \n",
        "# files.download(evaluation_data_path)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}